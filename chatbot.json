{"id":"58f61215-ab7f-4d97-aad9-0402deab9dd7","data":{"nodes":[{"id":"ChatInput-bhtCD","type":"genericNode","position":{"x":211,"y":480},"data":{"type":"ChatInput","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n\n    def build_config(self):\n        build_config = super().build_config()\n        build_config[\"input_value\"] = {\n            \"input_types\": [],\n            \"display_name\": \"Message\",\n            \"multiline\": True,\n        }\n\n        return build_config\n\n    def build(\n        self,\n        sender: Optional[str] = \"User\",\n        sender_name: Optional[str] = \"User\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n    ) -> Union[Text, Record]:\n        return super().build_no_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Message","advanced":false,"input_types":[],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"value":"can i jump and eat oily foods?"},"return_record":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_record","display_name":"Return Record","advanced":true,"dynamic":false,"info":"Return the message as a record containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"User","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":false,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"MySessionID"},"_type":"CustomComponent"},"description":"Get chat inputs from the Playground.","icon":"ChatInput","base_classes":["object","Record","str","Text"],"display_name":"Chat Input","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"return_record":null},"output_types":["Text","Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"name":"Chat Input"},"id":"ChatInput-bhtCD"},"selected":false,"width":384,"height":469,"dragging":false},{"id":"MemoryComponent-OgzZE","type":"genericNode","position":{"x":216.43147003329477,"y":-56.57892742633349},"data":{"type":"MemoryComponent","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.memory.memory import BaseMemoryComponent\nfrom langflow.field_typing import Text\nfrom langflow.helpers.record import records_to_text\nfrom langflow.memory import get_messages\nfrom langflow.schema.schema import Record\n\n\nclass MemoryComponent(BaseMemoryComponent):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages given a specific Session ID.\"\n    beta: bool = True\n    icon = \"history\"\n\n    def build_config(self):\n        return {\n            \"sender\": {\n                \"options\": [\"Machine\", \"User\", \"Machine and User\"],\n                \"display_name\": \"Sender Type\",\n            },\n            \"sender_name\": {\"display_name\": \"Sender Name\", \"advanced\": True},\n            \"n_messages\": {\n                \"display_name\": \"Number of Messages\",\n                \"info\": \"Number of messages to retrieve.\",\n            },\n            \"session_id\": {\n                \"display_name\": \"Session ID\",\n                \"info\": \"Session ID of the chat history.\",\n                \"input_types\": [\"Text\"],\n            },\n            \"order\": {\n                \"options\": [\"Ascending\", \"Descending\"],\n                \"display_name\": \"Order\",\n                \"info\": \"Order of the messages.\",\n                \"advanced\": True,\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def get_messages(self, **kwargs) -> list[Record]:\n        # Validate kwargs by checking if it contains the correct keys\n        if \"sender\" not in kwargs:\n            kwargs[\"sender\"] = None\n        if \"sender_name\" not in kwargs:\n            kwargs[\"sender_name\"] = None\n        if \"session_id\" not in kwargs:\n            kwargs[\"session_id\"] = None\n        if \"limit\" not in kwargs:\n            kwargs[\"limit\"] = 5\n        if \"order\" not in kwargs:\n            kwargs[\"order\"] = \"Descending\"\n\n        kwargs[\"order\"] = \"DESC\" if kwargs[\"order\"] == \"Descending\" else \"ASC\"\n        if kwargs[\"sender\"] == \"Machine and User\":\n            kwargs[\"sender\"] = None\n        return get_messages(**kwargs)\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine and User\",\n        sender_name: Optional[str] = None,\n        session_id: Optional[str] = None,\n        n_messages: int = 5,\n        order: Optional[str] = \"Descending\",\n        record_template: Optional[str] = \"{sender_name}: {text}\",\n    ) -> Text:\n        messages = self.get_messages(\n            sender=sender,\n            sender_name=sender_name,\n            session_id=session_id,\n            limit=n_messages,\n            order=order,\n        )\n        messages_str = records_to_text(template=record_template or \"\", records=messages)\n        self.status = messages_str\n        return messages_str\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"n_messages":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":5,"fileTypes":[],"file_path":"","password":false,"name":"n_messages","display_name":"Number of Messages","advanced":false,"dynamic":false,"info":"Number of messages to retrieve.","load_from_db":false,"title_case":false},"order":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Descending","fileTypes":[],"file_path":"","password":false,"options":["Ascending","Descending"],"name":"order","display_name":"Order","advanced":true,"dynamic":false,"info":"Order of the messages.","load_from_db":false,"title_case":false,"input_types":["Text"]},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"{sender_name}: {text}","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine and User","fileTypes":[],"file_path":"","password":false,"options":["Machine","User","Machine and User"],"name":"sender","display_name":"Sender Type","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":false,"input_types":["Text"],"dynamic":false,"info":"Session ID of the chat history.","load_from_db":false,"title_case":false,"value":""},"_type":"CustomComponent"},"description":"Retrieves stored chat messages given a specific Session ID.","icon":"history","base_classes":["object","str","Text"],"display_name":"Chat Memory","documentation":"","custom_fields":{"sender":null,"sender_name":null,"session_id":null,"n_messages":null,"order":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":true,"name":"Chat Memory"},"id":"MemoryComponent-OgzZE"},"selected":false,"width":384,"height":489,"positionAbsolute":{"x":216.43147003329477,"y":-56.57892742633349},"dragging":false},{"id":"TextOutput-4hDAv","type":"genericNode","position":{"x":952.9233394373707,"y":-149.63681870384275},"data":{"type":"TextOutput","node":{"template":{"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"","fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Value","advanced":false,"input_types":["Record","Text"],"dynamic":false,"info":"Text or Record to be passed as output.","load_from_db":false,"title_case":false},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\n\nfrom langflow.base.io.text import TextComponent\nfrom langflow.field_typing import Text\n\n\nclass TextOutput(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n\n    def build_config(self):\n        return {\n            \"input_value\": {\n                \"display_name\": \"Value\",\n                \"input_types\": [\"Record\", \"Text\"],\n                \"info\": \"Text or Record to be passed as output.\",\n            },\n            \"record_template\": {\n                \"display_name\": \"Record Template\",\n                \"multiline\": True,\n                \"info\": \"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.\",\n                \"advanced\": True,\n            },\n        }\n\n    def build(self, input_value: Optional[Text] = \"\", record_template: Optional[str] = \"\") -> Text:\n        return super().build(input_value=input_value, record_template=record_template)\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"Template to convert Record to Text. If left empty, it will be dynamically set to the Record's text key.","load_from_db":false,"title_case":false,"input_types":["Text"]},"_type":"CustomComponent"},"description":"Display a text output in the Playground.","icon":"type","base_classes":["object","str","Text"],"display_name":"Inspect Memory","documentation":"","custom_fields":{"input_value":null,"record_template":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"name":"Text Output"},"id":"TextOutput-4hDAv"},"selected":false,"width":384,"height":289,"dragging":false},{"id":"Prompt-bxr6x","type":"genericNode","position":{"x":956.2865430886818,"y":322.8177909129163},"data":{"type":"Prompt","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from langchain_core.prompts import PromptTemplate\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Prompt, TemplateField, Text\n\n\nclass PromptComponent(CustomComponent):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n\n    def build_config(self):\n        return {\n            \"template\": TemplateField(display_name=\"Template\"),\n            \"code\": TemplateField(advanced=True),\n        }\n\n    def build(\n        self,\n        template: Prompt,\n        **kwargs,\n    ) -> Text:\n        from langflow.base.prompts.utils import dict_values_to_string\n\n        prompt_template = PromptTemplate.from_template(Text(template))\n        kwargs = dict_values_to_string(kwargs)\n        kwargs = {k: \"\\n\".join(v) if isinstance(v, list) else v for k, v in kwargs.items()}\n        try:\n            formated_prompt = prompt_template.format(**kwargs)\n        except Exception as exc:\n            raise ValueError(f\"Error formatting prompt: {exc}\") from exc\n        self.status = f'Prompt:\\n\"{formated_prompt}\"'\n        return formated_prompt\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"template":{"type":"prompt","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"You are an expert healthcare professional with extensive knowledge in various health conditions and diseases. Your role is to provide accurate, evidence-based answers to the questions users ask about their health, diseases, or conditions. Respond to the user's concerns in an empathetic and supportive manner, as a caring nurse would. Use phrases like \"I understand,\" \"I'm here to help,\" and \"That sounds difficult.\" Guide them on how to manage their symptoms step-by-step or provide clear answers to their questions. Always ensure your responses are factual and based on the latest medical guidelines. Here are some examples of how to structure your responses:\n\n1. Acknowledge the user's feelings:\n   - \"I understand how challenging this must be for you.\"\n   - \"That sounds difficult, but I'm here to help you.\"\n\n2. Provide clear, factual information:\n   - \"Based on current medical guidelines, it's important to...\"\n   - \"Research shows that...\"\n\n3. Offer step-by-step guidance or answers:\n   - \"To manage your symptoms, you can try the following steps:...\"\n   - \"Here are some strategies that can help:...\"\n\n4. Encourage and support the user:\n   - \"Remember, you're not alone in this.\"\n   - \"If you have any more questions or need further assistance, feel free to ask.\"\n\nExample Interaction:\nUser: \"I have arthritis, so can I climb a flight of stairs?\"\nVirtual Nurse: \"I understand that dealing with arthritis can be very painful. It's important to listen to your body and not push yourself too hard. Generally, moderate physical activity can be beneficial for arthritis, but it's crucial to do it in a safe and controlled manner. Here are some tips to help you manage climbing stairs with arthritis:\n1. Take your time and go at a pace that feels comfortable.\n2. Use handrails for support if available.\n3. If possible, try to use the stronger leg to lead when going up, and the weaker leg when going down.\n4. Consider using assistive devices like a cane if needed.\nRemember to consult with your healthcare provider before making any changes to your physical activity routine.\"\n\nUser: \"I have been experiencing frequent headaches. What can I do to alleviate them?\"\nVirtual Nurse: \"I'm sorry to hear that you're experiencing frequent headaches. I understand how disruptive they can be. Here are some steps you can take to manage and potentially reduce your headaches:\n1. Stay hydrated by drinking plenty of water throughout the day.\n2. Ensure you are getting enough sleep and maintaining a regular sleep schedule.\n3. Try to identify and avoid potential triggers, such as certain foods, stress, or bright lights.\n4. Practice relaxation techniques like deep breathing, meditation, or gentle yoga.\n5. Over-the-counter pain relievers can be helpful, but make sure to use them as directed.\nIf your headaches persist or worsen, it's important to consult with a healthcare provider to rule out any underlying conditions.\"\n\nKeep your responses clear, concise, and compassionate. Your goal is to provide the best possible care and support to the users.\n\n{context}\n\nUser: {user_message}\nAI: ","fileTypes":[],"file_path":"","password":false,"name":"template","display_name":"Template","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"_type":"CustomComponent","context":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"context","display_name":"context","advanced":false,"input_types":["Document","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"},"user_message":{"field_type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"","fileTypes":[],"file_path":"","password":false,"name":"user_message","display_name":"user_message","advanced":false,"input_types":["Document","Record","Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false,"type":"str"}},"description":"Create a prompt template with dynamic variables.","icon":"prompts","is_input":null,"is_output":null,"is_composition":null,"base_classes":["object","str","Text"],"name":"Prompt","display_name":"Prompt","documentation":"","custom_fields":{"template":["context","user_message"]},"output_types":["Text"],"full_path":null,"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"error":null},"id":"Prompt-bxr6x","description":"Create a prompt template with dynamic variables.","display_name":"Prompt"},"selected":false,"width":384,"height":477,"positionAbsolute":{"x":956.2865430886818,"y":322.8177909129163},"dragging":false},{"id":"OpenAIModel-cMgzz","type":"genericNode","position":{"x":1713.1672374534264,"y":-17.36514455752939},"data":{"type":"OpenAIModel","node":{"template":{"input_value":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Input","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"],"value":""},"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional\r\n \r\nfrom langchain_openai import ChatOpenAI\r\nfrom pydantic.v1 import SecretStr\r\n \r\nfrom langflow.base.constants import STREAM_INFO_TEXT\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.base.models.openai_constants import MODEL_NAMES\r\nfrom langflow.field_typing import NestedDict, Text\r\n \r\n \r\nclass OpenAIModelComponent(LCModelComponent):\r\n    display_name = \"AIML API\"\r\n    description = \"Generates text using AI/ML API\"\r\n    icon = \"ChatInput\"\r\n \r\n    field_order = [\r\n        \"max_tokens\",\r\n        \"model_kwargs\",\r\n        \"model_name\",\r\n        \"openai_api_base\",\r\n        \"openai_api_key\",\r\n        \"temperature\",\r\n        \"input_value\",\r\n        \"system_message\",\r\n        \"stream\",\r\n    ]\r\n \r\n    def build_config(self):\r\n        return {\r\n            \"input_value\": {\"display_name\": \"Input\"},\r\n            \"max_tokens\": {\r\n                \"display_name\": \"Max Tokens\",\r\n                \"advanced\": True,\r\n                \"info\": \"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\r\n            },\r\n            \"model_kwargs\": {\r\n                \"display_name\": \"Model Kwargs\",\r\n                \"advanced\": True,\r\n            },\r\n            \"model_name\": {\r\n                \"display_name\": \"Model Name\",\r\n                \"advanced\": False,\r\n                \"options\": [\"gpt-3.5-turbo-16k-0613\", \"gpt-4o\", \"meta-llama/Llama-3-70b-chat-hf\", \"mistralai/Mistral-7B-Instruct-v0.2\", \"claude-3-5-sonnet-20240620\"\r\n    ],\r\n            },\r\n            \"openai_api_base\": {\r\n                \"display_name\": \"OpenAI API Base\",\r\n                \"advanced\": True,\r\n                \"info\": (\r\n                    \"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\\n\\n\"\r\n                    \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\"\r\n                ),\r\n            },\r\n            \"openai_api_key\": {\r\n                \"display_name\": \"OpenAI API Key\",\r\n                \"info\": \"The OpenAI API Key to use for the OpenAI model.\",\r\n                \"advanced\": False,\r\n                \"password\": True,\r\n            },\r\n            \"temperature\": {\r\n                \"display_name\": \"Temperature\",\r\n                \"advanced\": False,\r\n                \"value\": 0.1,\r\n            },\r\n            \"stream\": {\r\n                \"display_name\": \"Stream\",\r\n                \"info\": STREAM_INFO_TEXT,\r\n                \"advanced\": True,\r\n            },\r\n            \"system_message\": {\r\n                \"display_name\": \"System Message\",\r\n                \"info\": \"System message to pass to the model.\",\r\n                \"advanced\": True,\r\n            },\r\n        }\r\n \r\n    def build(\r\n        self,\r\n        input_value: Text,\r\n        openai_api_key: str,\r\n        temperature: float,\r\n        model_name: str = \"gpt-4o\",\r\n        max_tokens: Optional[int] = 256,\r\n        model_kwargs: NestedDict = {},\r\n        openai_api_base: Optional[str] = None,\r\n        stream: bool = False,\r\n        system_message: Optional[str] = None,\r\n    ) -> Text:\r\n        if not openai_api_base:\r\n            openai_api_base = \"https://api.aimlapi.com/v1\"\r\n        if openai_api_key:\r\n            api_key = SecretStr(openai_api_key)\r\n        else:\r\n            api_key = None\r\n \r\n        output = ChatOpenAI(\r\n            max_tokens=max_tokens or None,\r\n            model_kwargs=model_kwargs,\r\n            model=model_name,\r\n            base_url=openai_api_base,\r\n            api_key=api_key,\r\n            temperature=temperature,\r\n        )\r\n \r\n        return self.get_chat_result(output, stream, input_value, system_message)","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"max_tokens":{"type":"int","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":256,"fileTypes":[],"file_path":"","password":false,"name":"max_tokens","display_name":"Max Tokens","advanced":true,"dynamic":false,"info":"The maximum number of tokens to generate. Set to 0 for unlimited tokens.","load_from_db":false,"title_case":false},"model_kwargs":{"type":"NestedDict","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":{},"fileTypes":[],"file_path":"","password":false,"name":"model_kwargs","display_name":"Model Kwargs","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false},"model_name":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"gpt-4o","fileTypes":[],"file_path":"","password":false,"options":["gpt-3.5-turbo-16k-0613","gpt-4o","meta-llama/Llama-3-70b-chat-hf","mistralai/Mistral-7B-Instruct-v0.2","claude-3-5-sonnet-20240620"],"name":"model_name","display_name":"Model Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_base":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"openai_api_base","display_name":"OpenAI API Base","advanced":true,"dynamic":false,"info":"The base URL of the OpenAI API. Defaults to https://api.openai.com/v1.\n\nYou can change this to use other APIs like JinaChat, LocalAI and Prem.","load_from_db":false,"title_case":false,"input_types":["Text"]},"openai_api_key":{"type":"str","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":true,"name":"openai_api_key","display_name":"OpenAI API Key","advanced":false,"dynamic":false,"info":"The OpenAI API Key to use for the OpenAI model.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"12b9cf437b0142c5b4264bf7a72d74d0"},"stream":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"stream","display_name":"Stream","advanced":true,"dynamic":false,"info":"Stream the response from the model. Streaming works only in Chat.","load_from_db":false,"title_case":false},"system_message":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"system_message","display_name":"System Message","advanced":true,"dynamic":false,"info":"System message to pass to the model.","load_from_db":false,"title_case":false,"input_types":["Text"]},"temperature":{"type":"float","required":true,"placeholder":"","list":false,"show":true,"multiline":false,"value":0.1,"fileTypes":[],"file_path":"","password":false,"name":"temperature","display_name":"Temperature","advanced":false,"dynamic":false,"info":"","rangeSpec":{"step_type":"float","min":-1,"max":1,"step":0.1},"load_from_db":false,"title_case":false},"_type":"CustomComponent"},"description":"Generates text using AI/ML API","icon":"ChatInput","base_classes":["object","str","Text"],"display_name":"OpenAI","documentation":"","custom_fields":{"input_value":null,"openai_api_key":null,"temperature":null,"model_name":null,"max_tokens":null,"model_kwargs":null,"openai_api_base":null,"stream":null,"system_message":null},"output_types":["Text"],"field_formatters":{},"frozen":false,"field_order":["max_tokens","model_kwargs","model_name","openai_api_base","openai_api_key","temperature","input_value","system_message","stream"],"beta":false},"id":"OpenAIModel-cMgzz","description":"Generates text using AI/ML API","display_name":"OpenAI"},"selected":false,"width":384,"height":563,"positionAbsolute":{"x":1713.1672374534264,"y":-17.36514455752939},"dragging":false},{"id":"ChatOutput-JL4Y6","type":"genericNode","position":{"x":2290.4032641695635,"y":485.3896525660253},"data":{"type":"ChatOutput","node":{"template":{"code":{"type":"code","required":true,"placeholder":"","list":false,"show":true,"multiline":true,"value":"from typing import Optional, Union\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.field_typing import Text\nfrom langflow.schema import Record\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n\n    def build(\n        self,\n        sender: Optional[str] = \"Machine\",\n        sender_name: Optional[str] = \"AI\",\n        input_value: Optional[str] = None,\n        session_id: Optional[str] = None,\n        return_record: Optional[bool] = False,\n        record_template: Optional[str] = \"{text}\",\n    ) -> Union[Text, Record]:\n        return super().build_with_record(\n            sender=sender,\n            sender_name=sender_name,\n            input_value=input_value,\n            session_id=session_id,\n            return_record=return_record,\n            record_template=record_template or \"\",\n        )\n","fileTypes":[],"file_path":"","password":false,"name":"code","advanced":true,"dynamic":true,"info":"","load_from_db":false,"title_case":false},"input_value":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"fileTypes":[],"file_path":"","password":false,"name":"input_value","display_name":"Message","advanced":false,"input_types":["Text"],"dynamic":false,"info":"","load_from_db":false,"title_case":false},"record_template":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":true,"value":"{text}","fileTypes":[],"file_path":"","password":false,"name":"record_template","display_name":"Record Template","advanced":true,"dynamic":false,"info":"In case of Message being a Record, this template will be used to convert it to text.","load_from_db":false,"title_case":false,"input_types":["Text"]},"return_record":{"type":"bool","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":false,"fileTypes":[],"file_path":"","password":false,"name":"return_record","display_name":"Return Record","advanced":true,"dynamic":false,"info":"Return the message as a record containing the sender, sender_name, and session_id.","load_from_db":false,"title_case":false},"sender":{"type":"str","required":false,"placeholder":"","list":true,"show":true,"multiline":false,"value":"Machine","fileTypes":[],"file_path":"","password":false,"options":["Machine","User"],"name":"sender","display_name":"Sender Type","advanced":true,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"sender_name":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"value":"AI","fileTypes":[],"file_path":"","password":false,"name":"sender_name","display_name":"Sender Name","advanced":false,"dynamic":false,"info":"","load_from_db":false,"title_case":false,"input_types":["Text"]},"session_id":{"type":"str","required":false,"placeholder":"","list":false,"show":true,"multiline":false,"fileTypes":[],"file_path":"","password":false,"name":"session_id","display_name":"Session ID","advanced":false,"dynamic":false,"info":"If provided, the message will be stored in the memory.","load_from_db":false,"title_case":false,"input_types":["Text"],"value":"MySessionID"},"_type":"CustomComponent"},"description":"Display a chat message in the Playground.","icon":"ChatOutput","base_classes":["object","Record","str","Text"],"display_name":"Chat Output","documentation":"","custom_fields":{"sender":null,"sender_name":null,"input_value":null,"session_id":null,"return_record":null,"record_template":null},"output_types":["Text","Record"],"field_formatters":{},"frozen":false,"field_order":[],"beta":false,"name":"Chat Output"},"id":"ChatOutput-JL4Y6"},"selected":false,"width":384,"height":475,"dragging":false}],"edges":[{"source":"MemoryComponent-OgzZE","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œMemoryComponentœ,œidœ:œMemoryComponent-OgzZEœ}","target":"TextOutput-4hDAv","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-4hDAvœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"TextOutput-4hDAv","inputTypes":["Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"MemoryComponent","id":"MemoryComponent-OgzZE"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-MemoryComponent-OgzZE{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œMemoryComponentœ,œidœ:œMemoryComponent-OgzZEœ}-TextOutput-4hDAv{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-4hDAvœ,œinputTypesœ:[œRecordœ,œTextœ],œtypeœ:œstrœ}"},{"source":"MemoryComponent-OgzZE","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œMemoryComponentœ,œidœ:œMemoryComponent-OgzZEœ}","target":"Prompt-bxr6x","targetHandle":"{œfieldNameœ:œcontextœ,œidœ:œPrompt-bxr6xœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"context","id":"Prompt-bxr6x","inputTypes":["Document","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"MemoryComponent","id":"MemoryComponent-OgzZE"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-MemoryComponent-OgzZE{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œMemoryComponentœ,œidœ:œMemoryComponent-OgzZEœ}-Prompt-bxr6x{œfieldNameœ:œcontextœ,œidœ:œPrompt-bxr6xœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"},{"source":"ChatInput-bhtCD","sourceHandle":"{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-bhtCDœ}","target":"Prompt-bxr6x","targetHandle":"{œfieldNameœ:œuser_messageœ,œidœ:œPrompt-bxr6xœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"user_message","id":"Prompt-bxr6x","inputTypes":["Document","Record","Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","Record","str","Text"],"dataType":"ChatInput","id":"ChatInput-bhtCD"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-ChatInput-bhtCD{œbaseClassesœ:[œobjectœ,œRecordœ,œstrœ,œTextœ],œdataTypeœ:œChatInputœ,œidœ:œChatInput-bhtCDœ}-Prompt-bxr6x{œfieldNameœ:œuser_messageœ,œidœ:œPrompt-bxr6xœ,œinputTypesœ:[œDocumentœ,œRecordœ,œTextœ],œtypeœ:œstrœ}"},{"source":"Prompt-bxr6x","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-bxr6xœ}","target":"OpenAIModel-cMgzz","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-cMgzzœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"OpenAIModel-cMgzz","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"Prompt","id":"Prompt-bxr6x"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-Prompt-bxr6x{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œPromptœ,œidœ:œPrompt-bxr6xœ}-OpenAIModel-cMgzz{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-cMgzzœ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"},{"source":"OpenAIModel-cMgzz","sourceHandle":"{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-cMgzzœ}","target":"ChatOutput-JL4Y6","targetHandle":"{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-JL4Y6œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}","data":{"targetHandle":{"fieldName":"input_value","id":"ChatOutput-JL4Y6","inputTypes":["Text"],"type":"str"},"sourceHandle":{"baseClasses":["object","str","Text"],"dataType":"OpenAIModel","id":"OpenAIModel-cMgzz"}},"style":{"stroke":"#555"},"className":"stroke-gray-900 stroke-connection","id":"reactflow__edge-OpenAIModel-cMgzz{œbaseClassesœ:[œobjectœ,œstrœ,œTextœ],œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-cMgzzœ}-ChatOutput-JL4Y6{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-JL4Y6œ,œinputTypesœ:[œTextœ],œtypeœ:œstrœ}"}],"viewport":{"x":42.33285760556805,"y":130.539334422764,"zoom":0.435879119768531}},"description":"","name":"Empathetic Memory Chatbot","last_tested_version":"0.0.11","is_component":false}